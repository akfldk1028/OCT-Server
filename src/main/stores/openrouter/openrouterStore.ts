// main/stores/openrouter/openrouterStore.ts
import { createStore } from 'zustand/vanilla';
import { v4 as uuidv4 } from 'uuid';
import type { OpenRouterState, AIModel, StreamChunk, ModelsResponse, ModelPricing, OpenRouterConfig } from './openrouter-type';

export const openrouterStore = createStore<OpenRouterState>((set, get) => ({
  // Initial State - Mapì„ ëª¨ë‘ Recordë¡œ ë³€ê²½
  config: {
    endpoint: 'http://127.0.0.1:8787',
    defaultModel: 'openai/gpt-4',
    maxRetries: 3,
    timeout: 30000,
  },
  models: {},
  modelsLoading: false,
  modelsError: undefined,
  activeStreams: {},
  sessionUsage: {},

  // Initialize
  initialize: (config) => {
    console.log('ğŸš€ [openrouterStore] initialize í˜¸ì¶œ!');
    console.log('âš™ï¸ config:', config);
    set({ config: {
      endpoint: config.endpoint || 'http://127.0.0.1:8787',
      defaultModel: config.defaultModel || 'openai/gpt-4',
      maxRetries: config.maxRetries || 3,
      timeout: config.timeout || 30000,
    } });
    console.log('âœ… config ì„¸íŒ… ì™„ë£Œ!');
    get().fetchModels().then(() => {
      console.log('ğŸ“¦ ëª¨ë¸ ëª©ë¡ fetch ì™„ë£Œ!');
    }).catch((err) => {
      console.error('âŒ ëª¨ë¸ ëª©ë¡ fetch ì‹¤íŒ¨:', err);
    });
  },

  // Update Config
  updateConfig: (payload: { config?: Partial<OpenRouterConfig> }) => {
    const { config } = payload;
    console.log('ğŸš€ [openrouterStore] updateConfig í˜¸ì¶œ!');
    console.log('âš™ï¸ config:', config);
    set((state) => ({
      config: config ? { ...state.config, ...config } : state.config
    }));
  },

  // Fetch Models
  fetchModels: async () => {
    set({ modelsLoading: true, modelsError: undefined });
  
    try {
      const { endpoint, apiKey } = get().config;
  
      // 1) ë°±ì—”ë“œ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
      const response = await fetch(`${endpoint}/openrouter/models`, {
        headers: apiKey ? { Authorization: `Bearer ${apiKey}` } : {},
      });
  
      if (!response.ok) {
        throw new Error(`Failed to fetch models: ${response.statusText}`);
      }
  
      // 2) JSON íŒŒì‹± (AIModel[] ë°°ì—´ì„ í¬í•¨í•˜ëŠ” ì‘ë‹µ í˜•íƒœ)
      //    ë°±ì—”ë“œê°€ { total: number, models: AIModel[] } í˜•íƒœë¡œ ë‚´ë ¤ì¤€ë‹¤ê³  ê°€ì •
      const data = (await response.json()) as ModelsResponse;
      console.log(`ğŸ¤– [fetchModels] ëª¨ë¸ ${data.models.length}ê°œ ë°›ì•„ì˜´!`);
  
      const famousKeywords = ['gpt', 'claude', 'gemini', 'llama', 'mixtral'];

      const filteredModels = data.models.filter(rawModel =>
        famousKeywords.some(keyword => rawModel.id.toLowerCase().includes(keyword))
      );

      console.log(`ğŸ¤– [fetchModels] ëª¨ë¸ ${filteredModels.length}ê°œ ë°›ì•„ì˜´!`);

      // 3) rawModel(ì›ë³¸ AIModel íƒ€ì…)ì— ì—†ëŠ” vendor, supports~ í•„ë“œë¥¼ ê°€ê³µí•˜ì—¬
      //    ìµœì¢…ì ìœ¼ë¡œ "í”„ë¡ íŠ¸ì—ì„œ ì‚¬ìš©í•  AIModel"ì„ ì™„ì„±
      const modelsRecord: Record<string, AIModel> = {};

      filteredModels.forEach((rawModel) => {
        // ... (ê¸°ì¡´ ëª¨ë¸ ê°€ê³µ ì½”ë“œ ë™ì¼)
        // (A) vendor: id ì•ë¶€ë¶„
        const vendor = rawModel.id.split('/')[0];
        const supportsStreaming = true;
        const supportsTools =
          rawModel.id.includes('gpt-4') ||
          rawModel.id.includes('claude-3') ||
          rawModel.id.includes('gemini');
        const pricing: ModelPricing = {
          prompt: rawModel.pricing.prompt,
          completion: rawModel.pricing.completion,
          request: rawModel.pricing.request,
          image: rawModel.pricing.image,
          web_search: rawModel.pricing.web_search,
          internal_reasoning: rawModel.pricing.internal_reasoning,
          input_cache_read: rawModel.pricing.input_cache_read,
          input_cache_write: rawModel.pricing.input_cache_write,
        };
        const modelObj: AIModel = {
          id: rawModel.id,
          name: rawModel.name,
          created: rawModel.created,
          description: rawModel.description,
          context_length: rawModel.context_length,
          hugging_face_id: rawModel.hugging_face_id,
          architecture: rawModel.architecture,
          pricing,
          top_provider: rawModel.top_provider,
          per_request_limits: rawModel.per_request_limits,
          supported_parameters: rawModel.supported_parameters,
          vendor,
          supportsStreaming,
          supportsTools,
        };
        modelsRecord[rawModel.id] = modelObj;
        console.log(
          `  ğŸ·ï¸ ${modelObj.id} | ${modelObj.name} | ë²¤ë”: ${vendor} | ` +
            `í”„ë¡¬í”„íŠ¸ ë‹¨ê°€: ${parseFloat(pricing.prompt)}`
        );
      });

      // data.models.forEach((rawModel) => {
      //   // (A) vendor: id ì•ë¶€ë¶„ (ì˜ˆ: "deepseek/deepseek-..." â†’ "deepseek")
      //   const vendor = rawModel.id.split('/')[0];
  
      //   // (B) supportsStreaming: í•„ìš”í•˜ë‹¤ë©´ rawModel.architecture ë“±ì„ ë³´ê³  ê²°ì •í•˜ê±°ë‚˜, 
      //   //     ì—¬ê¸°ì„œëŠ” "ëª¨ë“  ëª¨ë¸ì´ ìŠ¤íŠ¸ë¦¬ë° ê°€ëŠ¥"ì´ë¼ ê°€ì •í•´ trueë¡œ ì„¤ì •
      //   const supportsStreaming = true;
  
      //   // (C) supportsTools: idì— íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨ ì‹œ true
      //   const supportsTools =
      //     rawModel.id.includes('gpt-4') ||
      //     rawModel.id.includes('claude-3') ||
      //     rawModel.id.includes('gemini');
  
      //   // (D) pricing: í•„ë“œë¥¼ ê·¸ëŒ€ë¡œ stringìœ¼ë¡œ ìœ ì§€í•˜ë˜,
      //   //     (í•„ìš”í•˜ë‹¤ë©´ parseFloatë¡œ ìˆ«ìí™”)
      //   const pricing: ModelPricing = {
      //     prompt: rawModel.pricing.prompt,
      //     completion: rawModel.pricing.completion,
      //     request: rawModel.pricing.request,
      //     image: rawModel.pricing.image,
      //     web_search: rawModel.pricing.web_search,
      //     internal_reasoning: rawModel.pricing.internal_reasoning,
      //     // rawModel.pricing.input_cache_read/â€¦ ê°€ ì¡´ì¬í•  ìˆ˜ë„ ìˆê³ , ì—†ì„ ìˆ˜ë„ ìˆìŒ
      //     input_cache_read: rawModel.pricing.input_cache_read,
      //     input_cache_write: rawModel.pricing.input_cache_write,
      //   };
  
      //   // (E) ìµœì¢… AIModel ê°ì²´ ì¡°ë¦½
      //   const modelObj: AIModel = {
      //     id: rawModel.id,
      //     name: rawModel.name,
      //     created: rawModel.created,
      //     description: rawModel.description,
      //     context_length: rawModel.context_length,
      //     hugging_face_id: rawModel.hugging_face_id,
      //     architecture: rawModel.architecture,
      //     pricing,
      //     top_provider: rawModel.top_provider,
      //     per_request_limits: rawModel.per_request_limits,
      //     supported_parameters: rawModel.supported_parameters,
      //     vendor,
      //     supportsStreaming,
      //     supportsTools,
      //   };
  
      //   modelsRecord[rawModel.id] = modelObj;
  
      //   console.log(
      //     `  ğŸ·ï¸ ${modelObj.id} | ${modelObj.name} | ë²¤ë”: ${vendor} | ` +
      //       `í”„ë¡¬í”„íŠ¸ ë‹¨ê°€: ${parseFloat(pricing.prompt)}`
      //   );
      // });
  
      // 4) Zustand ìƒíƒœ ì—…ë°ì´íŠ¸
      set({
        models: modelsRecord,
        modelsLoading: false,
      });
  
      // 5) ì»´í¬ë„ŒíŠ¸ì—ì„œ ì‚¬ìš©í•˜ê¸° í¸í•˜ë„ë¡ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜
      return Object.values(modelsRecord) as AIModel[];
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      set({
        modelsError: errorMessage,
        modelsLoading: false,
      });
      throw error;
    }
  },
  // Get Model
  getModel: (modelId) => {
    return get().models[modelId];
  },

  // Create Completion
  createCompletion: async (payload) => {
    const { model, messages, tools, temperature, maxTokens, sessionId } = payload;
    const { endpoint, apiKey, maxRetries, timeout } = get().config;
    let lastError: Error | undefined;

    for (let attempt = 0; attempt < maxRetries!; attempt++) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout!);

        const response = await fetch(`${endpoint}/openrouter/chat`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            ...(apiKey ? { Authorization: `Bearer ${apiKey}` } : {}),
          },
          body: JSON.stringify({
            model: model,
            messages: messages,
            tools: tools,
            temperature: temperature ?? 0.7,
            max_tokens: maxTokens,
          }),
          signal: controller.signal,
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
          throw new Error(`API error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();

        if (!data.success) {
          throw new Error(data.error || 'Unknown error');
        }

        // ì„¸ì…˜ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì 
        if (sessionId && data.usage) {
          set((state) => {
            const usage = state.sessionUsage[sessionId!] || {
              totalTokens: 0,
              totalCost: 0,
              requestCount: 0,
            };

            return {
              sessionUsage: {
                ...state.sessionUsage,
                [sessionId!]: {
                  totalTokens: usage.totalTokens + data.usage.total_tokens,
                  totalCost: usage.totalCost + (data.usage.total_cost || 0),
                  requestCount: usage.requestCount + 1,
                },
              },
            };
          });
        }

        return {
          content: data.response,
          toolCalls: data.toolCalls,
          usage: data.usage,
        };
      } catch (error) {
        lastError = error as Error;
        const err: any = error;
        if (err.name === 'AbortError') {
          throw new Error('Request timeout');
        }

        if (attempt < maxRetries! - 1) {
          await new Promise((resolve) => setTimeout(resolve, 2 ** attempt * 1000));
        }
      }
    }

    throw lastError || new Error('Max retries exceeded');
  },

  // Create Streaming Completion
  async *createStreamingCompletion(payload) {
    const { model, messages, tools, temperature, maxTokens, onChunk, sessionId } = payload;
    const content = payload.content ?? (messages && messages.length > 0 ? messages[messages.length - 1].content : '');
    const { endpoint, apiKey, timeout } = get().config;
    const streamId = 'Stream-' + uuidv4();
    const controller = new AbortController();

    // Register stream - Record ë°©ì‹ìœ¼ë¡œ
    set((state) => ({
      activeStreams: {
        ...state.activeStreams,
        [streamId]: controller,
      },
    }));

    try {
      const response = await fetch(`${endpoint}/openrouter/chat/stream`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(apiKey ? { Authorization: `Bearer ${apiKey}` } : {}),
        },
        body: JSON.stringify({
          sessionId,
          message: content,
          model: model,
          messages: messages,
          tools: tools,
          temperature: temperature ?? 0.7,
          max_tokens: maxTokens,
          stream: true,
        }),
        signal: controller.signal,
      });

      if (!response.ok) {
        throw new Error(`Stream error: ${response.status} ${response.statusText}`);
      }

      const reader = response.body?.getReader();
      if (!reader) throw new Error('No reader available');

      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6).trim();
            if (data === '[DONE]') continue;

            try {
              const chunk = JSON.parse(data) as StreamChunk;

              if (onChunk) {
                onChunk(chunk);
              }

              yield chunk;
            } catch (e) {
              console.error('Parse error:', e);
            }
          }
        }
      }

      yield { type: 'done' as const };
    } catch (error) {
      const err: any = error;
      if (err.name !== 'AbortError') {
        const errorChunk: StreamChunk = {
          type: 'error',
          error: error instanceof Error ? error.message : 'Unknown error',
        };
        if (onChunk) {
          onChunk(errorChunk);
        }
        yield errorChunk;
      }
    } finally {
      // Cleanup - Record ë°©ì‹ìœ¼ë¡œ
      set((state) => {
        const { [streamId]: removed, ...activeStreams } = state.activeStreams;
        return { activeStreams };
      });
    }
  },

  // Abort Stream
  abortStream: (streamId) => {
    const controller = get().activeStreams[streamId];
    if (controller) {
      controller.abort();

      set((state) => {
        const { [streamId]: removed, ...activeStreams } = state.activeStreams;
        return { activeStreams };
      });
    }
  },

  // Abort All Streams
  abortAllStreams: () => {
    const streams = get().activeStreams;
    Object.values(streams).forEach((controller) => controller.abort());
    set({ activeStreams: {} });
  },

  // Validate Model
  validateModel: (modelId) => {
    return modelId in get().models;
  },

  // Estimate Tokens
  estimateTokens: (messages) => {
    const totalChars = messages.reduce((sum, msg) => sum + msg.content.length, 0);
    return Math.ceil(totalChars / 4);
  },
}));