// ===== 3. ìˆ˜ì •ëœ ServerNodeExecutor =====
// main/workflow/executors/ServerNodeExecutor.ts

import { ServerNodeData } from '@/common/types/workflow';
import { BaseNodeExecutor } from './BaseNodeExecutor';
import { Logger } from '../logger';
import { ExecutePayload, ExecuteResult } from './node-executor-types';
import { IDesktopIntegration } from '../interfaces/workflow-interfaces';

export class ServerNodeExecutor extends BaseNodeExecutor<ServerNodeData> {
  constructor(
    node: ServerNodeData,
    private integration: IDesktopIntegration,
    logger?: Logger
  ) {
    super(node, logger);
  }
  
  protected async doExecute(payload: ExecutePayload): Promise<Partial<ExecuteResult>> {
    const { context, edges } = payload;
    const previousResults = context.getPreviousResults(String(this.node.id), edges);
    
    const message = await this.handlePreviousService(previousResults, context);
    
    return {
      data: {
        server: (this.node as any).data,
        connected: true
      },
      isLast: this.isLastNode(payload),
      message
    };
  }
  
  private async handlePreviousService(previousResults: any[], context: any): Promise<string> {
    // ì´ì „ ê²°ê³¼ì—ì„œ AI ì„œë¹„ìŠ¤ ì°¾ê¸°
    const aiService = this.findAIService(previousResults);
    
    if (aiService) {
      return await this.processAIService(aiService, context);
    }
    
    // ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ AI ì„œë¹„ìŠ¤ í™•ì¸ (í•˜ìœ„ ë…¸ë“œìš©)
    const existingAI = context.get('currentAI');
    if (existingAI) {
      return await this.processExistingAI(existingAI, context);
    }
    
    return 'ì„œë¹„ìŠ¤ ì—°ê²° ì™„ë£Œ';
  }

  private findAIService(previousResults: any[]): any {
    for (const result of previousResults) {
      const service = result?.data?.service;
      if (service?.name) {
        return service;
      }
    }
    return null;
  }

  private async processAIService(service: any, context: any): Promise<string> {
    switch (service.name) {
      case 'Claude AI':
      case 'Anthropic':
      case 'Claude':
        this.logger.info('ğŸ§  Claude ì„œë¹„ìŠ¤ ê°ì§€!');
        context.set('currentAI', service);
        const claudeResult = await this.connectClaudeMCPServer();
        return claudeResult.message;
        
      case 'OpenAI':
      case 'ChatGPT':
      case 'GPT-4':
      case 'GPT-3.5':
        this.logger.info('ğŸ”§ OpenAI ì„œë¹„ìŠ¤ ê°ì§€!');
        context.set('currentAI', service);
        return await this.connectOpenAIServer();
        
      case 'Gemini':
      case 'Google AI':
        this.logger.info('ğŸŒŸ Google AI ì„œë¹„ìŠ¤ ê°ì§€!');
        context.set('currentAI', service);
        return await this.connectGeminiServer();
        
      case 'Llama':
      case 'Meta AI':
        this.logger.info('ğŸ¦™ Meta AI ì„œë¹„ìŠ¤ ê°ì§€!');
        context.set('currentAI', service);
        return await this.connectLlamaServer();
        
      default:
        this.logger.debug(`â“ ì•Œ ìˆ˜ ì—†ëŠ” ì„œë¹„ìŠ¤: ${service.name}`);
        return `${service.name} ì—°ê²° ì™„ë£Œ (ì§€ì› ì˜ˆì •)`;
    }
  }

  private async processExistingAI(service: any, context: any): Promise<string> {
    this.logger.info(`ğŸ”— ê¸°ì¡´ ${service.name} ì—°ê²° â†’ ì¶”ê°€ ì„œë²„ ì—°ê²°`);
    
    switch (service.name) {
      case 'Claude AI':
      case 'Anthropic':
      case 'Claude':
        const claudeResult = await this.connectClaudeMCPServer();
        return claudeResult.message;
        
      case 'OpenAI':
      case 'ChatGPT':
      case 'GPT-4':
      case 'GPT-3.5':
        return await this.connectOpenAIServer();
        
      case 'Gemini':
      case 'Google AI':
        return await this.connectGeminiServer();
        
      case 'Llama':
      case 'Meta AI':
        return await this.connectLlamaServer();
        
      default:
        return `${service.name} ì¶”ê°€ ì—°ê²° ì™„ë£Œ`;
    }
  }

  private async connectOpenAIServer(): Promise<string> {
    // OpenAI ì„œë²„ ì—°ê²° ë¡œì§
    return 'ğŸ”§ OpenAI ì„œë²„ ì—°ê²° ì™„ë£Œ';
  }

  private async connectGeminiServer(): Promise<string> {
    // Gemini ì„œë²„ ì—°ê²° ë¡œì§
    return 'ğŸŒŸ Gemini ì„œë²„ ì—°ê²° ì™„ë£Œ';
  }

  private async connectLlamaServer(): Promise<string> {
    // Llama ì„œë²„ ì—°ê²° ë¡œì§
    return 'ğŸ¦™ Llama ì„œë²„ ì—°ê²° ì™„ë£Œ';
  }
  
  private async connectClaudeMCPServer(): Promise<{ message: string }> {
    try {
      const nodeData = (this.node as any).data;
      const serverInfo = nodeData?.mcp_servers;
      const mcpConfigs = nodeData?.mcp_configs;
      
      if (!serverInfo || !mcpConfigs?.length) {
        return { message: 'âš ï¸ MCP ì„¤ì • ì—†ìŒ' };
      }
      
      const platform = process.platform;
      
      switch (platform) {
        case 'win32':
          return await this.connectMCPWindows(serverInfo, mcpConfigs);
        case 'darwin':
          return await this.connectMCPMacOS(serverInfo, mcpConfigs);
        case 'linux':
          return await this.connectMCPLinux(serverInfo, mcpConfigs);
        default:
          return { message: `âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í”Œë«í¼: ${platform}` };
      }
      
    } catch (error) {
      this.logger.error('MCP ì—°ê²° ì˜¤ë¥˜:', error);
      return { message: `âŒ ì—°ê²° ì˜¤ë¥˜: ${error}` };
    }
  }

  private async connectMCPWindows(serverInfo: any, mcpConfigs: any[]): Promise<{ message: string }> {
    this.logger.info('ğŸªŸ Windows MCP ì—°ê²° ì‹œì‘');
    
    const serverName = serverInfo.name;
    if (this.integration.isServerConnected(serverName)) {
      return { message: `âœ… ì´ë¯¸ ì—°ê²°ë¨: ${serverName}` };
    }
    
    const config = this.selectBestConfigForWindows(mcpConfigs);
    if (!config) {
      return { message: 'âŒ Windows í˜¸í™˜ ì„¤ì • ì—†ìŒ' };
    }
    
    const serverConfig = {
      command: config.command,
      args: config.args || [],
      ...(config.env && { env: config.env })
    };
    
    const success = this.integration.connectServer(serverName, serverConfig);
    return {
      message: success 
        ? `ğŸ‰ ${serverName} Windowsì— ì¶”ê°€ë¨! Claude Desktop ì¬ì‹œì‘ í•„ìš”`
        : `âŒ Windows ì—°ê²° ì‹¤íŒ¨: ${serverName}`
    };
  }

  private async connectMCPMacOS(serverInfo: any, mcpConfigs: any[]): Promise<{ message: string }> {
    this.logger.info('ğŸ macOS MCP ì—°ê²° ì‹œì‘');
    
    const serverName = serverInfo.name;
    if (this.integration.isServerConnected(serverName)) {
      return { message: `âœ… ì´ë¯¸ ì—°ê²°ë¨: ${serverName}` };
    }
    
    const config = this.selectBestConfigForMacOS(mcpConfigs);
    if (!config) {
      return { message: 'âŒ macOS í˜¸í™˜ ì„¤ì • ì—†ìŒ' };
    }
    
    const serverConfig = {
      command: config.command,
      args: config.args || [],
      ...(config.env && { env: config.env })
    };
    
    const success = this.integration.connectServer(serverName, serverConfig);
    return {
      message: success 
        ? `ğŸ‰ ${serverName} macOSì— ì¶”ê°€ë¨! Claude Desktop ì¬ì‹œì‘ í•„ìš”`
        : `âŒ macOS ì—°ê²° ì‹¤íŒ¨: ${serverName}`
    };
  }

  private async connectMCPLinux(serverInfo: any, mcpConfigs: any[]): Promise<{ message: string }> {
    this.logger.info('ğŸ§ Linux MCP ì—°ê²° ì‹œì‘');
    
    const serverName = serverInfo.name;
    if (this.integration.isServerConnected(serverName)) {
      return { message: `âœ… ì´ë¯¸ ì—°ê²°ë¨: ${serverName}` };
    }
    
    const config = this.selectBestConfigForLinux(mcpConfigs);
    if (!config) {
      return { message: 'âŒ Linux í˜¸í™˜ ì„¤ì • ì—†ìŒ' };
    }
    
    const serverConfig = {
      command: config.command,
      args: config.args || [],
      ...(config.env && { env: config.env })
    };
    
    const success = this.integration.connectServer(serverName, serverConfig);
    return {
      message: success 
        ? `ğŸ‰ ${serverName} Linuxì— ì¶”ê°€ë¨! Claude Desktop ì¬ì‹œì‘ í•„ìš”`
        : `âŒ Linux ì—°ê²° ì‹¤íŒ¨: ${serverName}`
    };
  }
  
  private selectBestConfigForWindows(configs: any[]): any {
    // Windows ìš°ì„ ìˆœìœ„ (ë¹„ê°œë°œì ì¹œí™”ì ): npx > npm > pip > uvx > uv > python > docker
    const priorities = ['npx', 'npm', 'pip', 'uvx', 'uv', 'python', 'docker'];
    
    // ğŸ”¥ ê°•ì œë¡œ ìˆœì„œëŒ€ë¡œë§Œ í™•ì¸ - is_recommended ì™„ì „ ë¬´ì‹œ
    for (const priority of priorities) {
      const config = configs.find(c => c.command === priority);
      if (config) return config;
    }
    
    // ìœ„ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸
    return configs[0] || null;
  }

  private selectBestConfigForMacOS(configs: any[]): any {
    // macOS ìš°ì„ ìˆœìœ„ (ë¹„ê°œë°œì ì¹œí™”ì ): npx > npm > pip > uvx > uv > python > docker
    const priorities = ['npx', 'npm', 'pip', 'uvx', 'uv', 'python', 'docker'];
    
    // ğŸ”¥ ê°•ì œë¡œ ìˆœì„œëŒ€ë¡œë§Œ í™•ì¸ - is_recommended ì™„ì „ ë¬´ì‹œ
    for (const priority of priorities) {
      const config = configs.find(c => c.command === priority);
      if (config) return config;
    }
    
    // ìœ„ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸
    return configs[0] || null;
  }

  private selectBestConfigForLinux(configs: any[]): any {
    // Linux ìš°ì„ ìˆœìœ„ (ë¹„ê°œë°œì ì¹œí™”ì ): npx > npm > pip > uvx > uv > python > docker
    const priorities = ['npx', 'npm', 'pip', 'uvx', 'uv', 'python', 'docker'];
    
    // ğŸ”¥ ê°•ì œë¡œ ìˆœì„œëŒ€ë¡œë§Œ í™•ì¸ - is_recommended ì™„ì „ ë¬´ì‹œ
    for (const priority of priorities) {
      const config = configs.find(c => c.command === priority);
      if (config) return config;
    }
    
    // ìœ„ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸
    return configs[0] || null;
  }
}